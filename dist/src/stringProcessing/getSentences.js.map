{"version":3,"sources":["../../../src/stringProcessing/getSentences.js"],"names":["filter","flatMap","isEmpty","negate","memoize","getBlocks","unifyNonBreakingSpace","unifyWhitespace","SentenceTokenizer","newLines","newLineRegex","RegExp","getSentencesFromBlock","block","sentenceTokenizer","tokenizer","tokens","createTokenizer","tokenize","length","getSentencesFromTokens","getSentencesFromBlockCached","text","blocks","split","sentences"],"mappings":"AAAA;AACA,SAASA,MAAT,QAAuB,WAAvB;AACA,SAASC,OAAT,QAAwB,WAAxB;AACA,SAASC,OAAT,QAAwB,WAAxB;AACA,SAASC,MAAT,QAAuB,WAAvB;AACA,SAASC,OAAT,QAAwB,WAAxB;;AAEA;AACA,SAASC,SAAT,QAA0B,oBAA1B;AACA,SAASC,yBAAyBC,eAAlC,QAAyD,wCAAzD;AACA,OAAOC,iBAAP,MAA8B,qBAA9B;;AAEA;AACA,MAAMC,WAAW,YAAjB;;AAEA;AACA,MAAMC,eAAe,IAAIC,MAAJ,CAAYF,QAAZ,CAArB;;AAEA;;;;;;AAMA,SAASG,qBAAT,CAAgCC,KAAhC,EAAwC;AACvC,OAAMC,oBAAoB,IAAIN,iBAAJ,EAA1B;AACA,OAAM,EAAEO,SAAF,EAAaC,MAAb,KAAwBF,kBAAkBG,eAAlB,EAA9B;AACAH,mBAAkBI,QAAlB,CAA4BH,SAA5B,EAAuCF,KAAvC;;AAEA,QAAOG,OAAOG,MAAP,KAAkB,CAAlB,GAAsB,EAAtB,GAA2BL,kBAAkBM,sBAAlB,CAA0CJ,MAA1C,CAAlC;AACA;;AAED,MAAMK,8BAA8BjB,QAASQ,qBAAT,CAApC;;AAEA;;;;;;AAMA,eAAe,UAAUU,IAAV,EAAiB;AAC/BA,QAAOf,gBAAiBe,IAAjB,CAAP;AACA,KAAIC,SAASlB,UAAWiB,IAAX,CAAb;;AAEA;AACAC,UAAStB,QAASsB,MAAT,EAAiB,UAAUV,KAAV,EAAkB;AAC3C,SAAOA,MAAMW,KAAN,CAAad,YAAb,CAAP;AACA,EAFQ,CAAT;;AAIA,OAAMe,YAAYxB,QAASsB,MAAT,EAAiBF,2BAAjB,CAAlB;;AAEA,QAAOrB,OAAQyB,SAAR,EAAmBtB,OAAQD,OAAR,CAAnB,CAAP;AACA","file":"getSentences.js","sourcesContent":["// Lodash imports.\nimport { filter } from \"lodash-es\";\nimport { flatMap } from \"lodash-es\";\nimport { isEmpty } from \"lodash-es\";\nimport { negate } from \"lodash-es\";\nimport { memoize } from \"lodash-es\";\n\n// Internal dependencies.\nimport { getBlocks } from \"../helpers/html.js\";\nimport { unifyNonBreakingSpace as unifyWhitespace } from \"../stringProcessing/unifyWhitespace.js\";\nimport SentenceTokenizer from \"./SentenceTokenizer\";\n\n// Character classes.\nconst newLines = \"\\n\\r|\\n|\\r\";\n\n// Regular expressions.\nconst newLineRegex = new RegExp( newLines );\n\n/**\n * Returns the sentences from a certain block.\n *\n * @param {string} block The HTML inside a HTML block.\n * @returns {Array<string>} The list of sentences in the block.\n */\nfunction getSentencesFromBlock( block ) {\n\tconst sentenceTokenizer = new SentenceTokenizer();\n\tconst { tokenizer, tokens } = sentenceTokenizer.createTokenizer();\n\tsentenceTokenizer.tokenize( tokenizer, block );\n\n\treturn tokens.length === 0 ? [] : sentenceTokenizer.getSentencesFromTokens( tokens );\n}\n\nconst getSentencesFromBlockCached = memoize( getSentencesFromBlock );\n\n/**\n * Returns sentences in a string.\n *\n * @param {String} text The string to count sentences in.\n * @returns {Array} Sentences found in the text.\n */\nexport default function( text ) {\n\ttext = unifyWhitespace( text );\n\tlet blocks = getBlocks( text );\n\n\t// Split each block on newlines.\n\tblocks = flatMap( blocks, function( block ) {\n\t\treturn block.split( newLineRegex );\n\t} );\n\n\tconst sentences = flatMap( blocks, getSentencesFromBlockCached );\n\n\treturn filter( sentences, negate( isEmpty ) );\n}\n"]}